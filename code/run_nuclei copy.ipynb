{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"cyto3\", \"nuclei\", \"cyto2_cp3\", \"tissuenet_cp3\", \"livecell_cp3\", \"yeast_PhC_cp3\",\n",
    "    \"yeast_BF_cp3\", \"bact_phase_cp3\", \"bact_fluor_cp3\", \"deepbacs_cp3\", \"cyto2\", \"cyto\", \"CPx\",\n",
    "    \"transformer_cp3\", \"neurips_cellpose_default\", \"neurips_cellpose_transformer\",\n",
    "    \"neurips_grayscale_cyto2\"\n",
    "]\n",
    "\n",
    "save_path = '/root/capsule/scratch/'\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    model_save_path = os.path.join(save_path, model_name)\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:18:46,494 [INFO] WRITING LOG OUTPUT TO /root/.cellpose/run.log\n",
      "2024-09-15 20:18:46,495 [INFO] \n",
      "cellpose version: \t3.0.11 \n",
      "platform:       \tlinux \n",
      "python version: \t3.10.12 \n",
      "torch version:  \t2.1.0\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cellpose import models, train, io\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import plot\n",
    "from cellpose import utils, io\n",
    "\n",
    "io.logger_setup()  # Run this to get printing of progress\n",
    "\n",
    "# Define paths\n",
    "data_dir = '/root/capsule/data/iGluSnFR_Soma_Annotation'\n",
    "\n",
    "# Collect all image and mask file paths\n",
    "image_files = sorted([f for f in os.listdir(data_dir) if f.endswith('_merged.tif')])\n",
    "mask_files = sorted([f for f in os.listdir(data_dir) if f.endswith('_segmented_v2.tif')])\n",
    "\n",
    "# Ensure that each image has a corresponding mask\n",
    "assert len(image_files) == len(mask_files), \"Number of images and masks must match.\"\n",
    "\n",
    "# Load all images and masks\n",
    "images = [tifffile.imread(os.path.join(data_dir, img))[:, 1, :, :] for img in image_files]\n",
    "masks = [tifffile.imread(os.path.join(data_dir, msk)) for msk in mask_files]\n",
    "\n",
    "# Ensure images and masks have the same number of frames\n",
    "for img, msk in zip(images, masks):\n",
    "    assert img.shape[0] == msk.shape[0], \"Number of frames in images and masks must match.\"\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.concatenate(images, axis=0)\n",
    "masks = np.concatenate(masks, axis=0)\n",
    "\n",
    "# Normalize images to 0-1 range\n",
    "images = images.astype(np.float32) / 255.0\n",
    "\n",
    "# Convert masks to uint8 if needed\n",
    "masks_uint8 = masks.astype(np.uint8)\n",
    "\n",
    "# Define an augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, p=0.5),\n",
    "], is_check_shapes=False)\n",
    "\n",
    "augmented_images = []\n",
    "augmented_masks = []\n",
    "\n",
    "# Augment each image multiple times\n",
    "num_augmentations = 5  # Number of times to augment each image\n",
    "\n",
    "for img, msk in zip(images, masks_uint8):\n",
    "    for _ in range(num_augmentations):\n",
    "        # Apply the augmentation pipeline\n",
    "        transformed = transform(image=img, mask=msk)\n",
    "        augmented_images.append(transformed['image'])\n",
    "        augmented_masks.append(transformed['mask'])\n",
    "\n",
    "# Convert lists to numpy arrays and combine with original data\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_masks = np.array(augmented_masks)\n",
    "\n",
    "# Combine original and augmented data\n",
    "images_combined = np.concatenate((images, augmented_images), axis=0)\n",
    "masks_combined = np.concatenate((masks_uint8, augmented_masks), axis=0)\n",
    "\n",
    "# Split data into train+val and test\n",
    "train_val_images, test_images, train_val_masks, test_masks = train_test_split(\n",
    "    images_combined, masks_combined, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# Split train+val into train and validation\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "    train_val_images, train_val_masks, test_size=0.176, random_state=42  # 0.176 to make validation 15% of total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:18:53,092 [INFO] >> cyto3 << model set to be used\n",
      "2024-09-15 20:18:54,010 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2024-09-15 20:18:54,010 [INFO] >>>> using GPU (CUDA)\n",
      "2024-09-15 20:18:54,095 [INFO] >>>> loading model /root/.cellpose/models/cyto3\n",
      "2024-09-15 20:18:54,144 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      "2024-09-15 20:18:54,145 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 43/705 [00:03<00:44, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:18:58,908 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 63/705 [00:04<00:39, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:18:59,953 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 103/705 [00:06<00:27, 21.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:01,935 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 134/705 [00:08<00:39, 14.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:04,288 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 144/705 [00:09<00:27, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:04,692 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 171/705 [00:10<00:33, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:06,123 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 209/705 [00:13<00:55,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:09,095 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 292/705 [00:18<00:20, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:13,894 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 298/705 [00:18<00:24, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:14,183 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 302/705 [00:19<00:20, 19.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:14,366 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 391/705 [00:24<00:17, 17.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:20,005 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 397/705 [00:24<00:15, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:20,299 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 432/705 [00:26<00:18, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:22,235 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 474/705 [00:29<00:15, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:24,647 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 485/705 [00:30<00:16, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:25,574 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 515/705 [00:32<00:13, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:27,557 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 527/705 [00:33<00:12, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:28,410 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 646/705 [00:39<00:03, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:35,219 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 701/705 [00:43<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:38,685 [WARNING] empty masks!\n",
      "2024-09-15 20:19:38,780 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [00:43<00:00, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:38,785 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 53/151 [00:03<00:04, 20.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:42,093 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 57/151 [00:03<00:04, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:42,380 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 72/151 [00:04<00:03, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:43,134 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 79/151 [00:04<00:04, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:43,556 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 86/151 [00:04<00:03, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:43,784 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 128/151 [00:07<00:01, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:46,582 [WARNING] empty masks!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151/151 [00:08<00:00, 17.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:47,734 [INFO] >>> computing diameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 44/705 [00:00<00:03, 218.83it/s]/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 705/705 [00:03<00:00, 217.85it/s]\n",
      "100%|██████████| 151/151 [00:00<00:00, 218.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:19:51,667 [WARNING] 121 train images with number of masks less than min_train_masks (5), removing from train set\n",
      "2024-09-15 20:19:51,668 [INFO] >>> using channels [0, 0]\n",
      "2024-09-15 20:19:51,668 [INFO] >>> normalizing {'lowhigh': None, 'percentile': None, 'normalize': True, 'norm3D': False, 'sharpen_radius': 0, 'smooth_radius': 0, 'tile_norm_blocksize': 0, 'tile_norm_smooth3D': 1, 'invert': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:20:18,317 [INFO] >>> n_epochs=1000, n_train=584, n_test=151\n",
      "2024-09-15 20:20:18,317 [INFO] >>> AdamW, learning_rate=0.10000, weight_decay=0.00010\n",
      "2024-09-15 20:20:18,558 [INFO] >>> saving model to /root/capsule/scratch/models/cyto3_cellpose_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15 20:20:32,862 [INFO] 0, train_loss=0.6359, test_loss=0.6461, LR=0.0000, time 14.31s\n",
      "2024-09-15 20:21:31,721 [INFO] 5, train_loss=0.0943, test_loss=0.0749, LR=0.0556, time 73.16s\n",
      "2024-09-15 20:22:30,486 [INFO] 10, train_loss=0.0794, test_loss=0.0722, LR=0.1000, time 131.93s\n",
      "2024-09-15 20:24:27,006 [INFO] 20, train_loss=0.0747, test_loss=0.0725, LR=0.1000, time 248.45s\n",
      "2024-09-15 20:26:22,696 [INFO] 30, train_loss=0.0714, test_loss=0.0607, LR=0.1000, time 364.14s\n",
      "2024-09-15 20:28:18,913 [INFO] 40, train_loss=0.0697, test_loss=0.0734, LR=0.1000, time 480.36s\n",
      "2024-09-15 20:30:14,948 [INFO] 50, train_loss=0.0701, test_loss=0.0750, LR=0.1000, time 596.39s\n",
      "2024-09-15 20:32:11,295 [INFO] 60, train_loss=0.0718, test_loss=0.0676, LR=0.1000, time 712.74s\n",
      "2024-09-15 20:34:07,378 [INFO] 70, train_loss=0.0708, test_loss=0.0603, LR=0.1000, time 828.82s\n",
      "2024-09-15 20:36:03,608 [INFO] 80, train_loss=0.0701, test_loss=0.0624, LR=0.1000, time 945.05s\n",
      "2024-09-15 20:37:59,952 [INFO] 90, train_loss=0.0692, test_loss=0.0704, LR=0.1000, time 1061.40s\n",
      "2024-09-15 20:39:56,041 [INFO] 100, train_loss=0.0663, test_loss=0.0733, LR=0.1000, time 1177.48s\n",
      "2024-09-15 20:41:52,467 [INFO] 110, train_loss=0.0674, test_loss=0.0598, LR=0.1000, time 1293.91s\n",
      "2024-09-15 20:43:49,080 [INFO] 120, train_loss=0.0667, test_loss=0.0635, LR=0.1000, time 1410.52s\n",
      "2024-09-15 20:45:45,700 [INFO] 130, train_loss=0.0633, test_loss=0.0575, LR=0.1000, time 1527.14s\n",
      "2024-09-15 20:47:42,536 [INFO] 140, train_loss=0.0637, test_loss=0.0551, LR=0.1000, time 1643.98s\n",
      "2024-09-15 20:49:38,947 [INFO] 150, train_loss=0.0630, test_loss=0.0591, LR=0.1000, time 1760.39s\n",
      "2024-09-15 20:51:35,306 [INFO] 160, train_loss=0.0610, test_loss=0.0664, LR=0.1000, time 1876.75s\n",
      "2024-09-15 20:53:31,890 [INFO] 170, train_loss=0.0579, test_loss=0.0522, LR=0.1000, time 1993.33s\n",
      "2024-09-15 20:55:28,323 [INFO] 180, train_loss=0.0576, test_loss=0.0546, LR=0.1000, time 2109.77s\n",
      "2024-09-15 20:57:24,872 [INFO] 190, train_loss=0.0552, test_loss=0.0581, LR=0.1000, time 2226.32s\n",
      "2024-09-15 20:59:21,109 [INFO] 200, train_loss=0.0555, test_loss=0.0525, LR=0.1000, time 2342.55s\n",
      "2024-09-15 21:01:17,534 [INFO] 210, train_loss=0.0540, test_loss=0.0503, LR=0.1000, time 2458.98s\n",
      "2024-09-15 21:03:13,809 [INFO] 220, train_loss=0.0530, test_loss=0.0538, LR=0.1000, time 2575.25s\n",
      "2024-09-15 21:05:10,032 [INFO] 230, train_loss=0.0522, test_loss=0.0485, LR=0.1000, time 2691.48s\n",
      "2024-09-15 21:07:06,429 [INFO] 240, train_loss=0.0522, test_loss=0.0472, LR=0.1000, time 2807.87s\n",
      "2024-09-15 21:09:02,980 [INFO] 250, train_loss=0.0498, test_loss=0.0515, LR=0.1000, time 2924.42s\n",
      "2024-09-15 21:10:59,470 [INFO] 260, train_loss=0.0493, test_loss=0.0468, LR=0.1000, time 3040.91s\n",
      "2024-09-15 21:12:55,516 [INFO] 270, train_loss=0.0497, test_loss=0.0488, LR=0.1000, time 3156.96s\n",
      "2024-09-15 21:14:51,933 [INFO] 280, train_loss=0.0492, test_loss=0.0506, LR=0.1000, time 3273.38s\n",
      "2024-09-15 21:16:48,018 [INFO] 290, train_loss=0.0471, test_loss=0.0452, LR=0.1000, time 3389.46s\n",
      "2024-09-15 21:18:44,520 [INFO] 300, train_loss=0.0458, test_loss=0.0455, LR=0.1000, time 3505.96s\n",
      "2024-09-15 21:20:41,061 [INFO] 310, train_loss=0.0457, test_loss=0.0453, LR=0.1000, time 3622.50s\n",
      "2024-09-15 21:22:37,417 [INFO] 320, train_loss=0.0466, test_loss=0.0408, LR=0.1000, time 3738.86s\n",
      "2024-09-15 21:24:33,415 [INFO] 330, train_loss=0.0444, test_loss=0.0499, LR=0.1000, time 3854.86s\n",
      "2024-09-15 21:26:30,232 [INFO] 340, train_loss=0.0451, test_loss=0.0499, LR=0.1000, time 3971.67s\n",
      "2024-09-15 21:28:26,511 [INFO] 350, train_loss=0.0447, test_loss=0.0453, LR=0.1000, time 4087.95s\n",
      "2024-09-15 21:30:23,442 [INFO] 360, train_loss=0.0433, test_loss=0.0475, LR=0.1000, time 4204.88s\n",
      "2024-09-15 21:32:19,985 [INFO] 370, train_loss=0.0438, test_loss=0.0401, LR=0.1000, time 4321.43s\n",
      "2024-09-15 21:34:16,396 [INFO] 380, train_loss=0.0435, test_loss=0.0361, LR=0.1000, time 4437.84s\n",
      "2024-09-15 21:36:12,819 [INFO] 390, train_loss=0.0427, test_loss=0.0402, LR=0.1000, time 4554.26s\n",
      "2024-09-15 21:38:08,899 [INFO] 400, train_loss=0.0421, test_loss=0.0399, LR=0.1000, time 4670.34s\n",
      "2024-09-15 21:40:05,637 [INFO] 410, train_loss=0.0408, test_loss=0.0391, LR=0.1000, time 4787.08s\n",
      "2024-09-15 21:42:02,224 [INFO] 420, train_loss=0.0412, test_loss=0.0403, LR=0.1000, time 4903.67s\n",
      "2024-09-15 21:43:58,546 [INFO] 430, train_loss=0.0409, test_loss=0.0476, LR=0.1000, time 5019.99s\n",
      "2024-09-15 21:45:55,028 [INFO] 440, train_loss=0.0403, test_loss=0.0421, LR=0.1000, time 5136.47s\n",
      "2024-09-15 21:47:51,213 [INFO] 450, train_loss=0.0412, test_loss=0.0418, LR=0.1000, time 5252.66s\n",
      "2024-09-15 21:49:47,542 [INFO] 460, train_loss=0.0411, test_loss=0.0415, LR=0.1000, time 5368.98s\n",
      "2024-09-15 21:51:43,847 [INFO] 470, train_loss=0.0381, test_loss=0.0378, LR=0.1000, time 5485.29s\n",
      "2024-09-15 21:53:40,223 [INFO] 480, train_loss=0.0403, test_loss=0.0398, LR=0.1000, time 5601.67s\n",
      "2024-09-15 21:55:36,565 [INFO] 490, train_loss=0.0392, test_loss=0.0409, LR=0.1000, time 5718.01s\n",
      "2024-09-15 21:57:33,049 [INFO] 500, train_loss=0.0400, test_loss=0.0377, LR=0.1000, time 5834.49s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import models, train, io\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Initialize an empty DataFrame to hold all results\n",
    "all_results_df = pd.DataFrame()\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    # Initialize Cellpose model\n",
    "    model = models.CellposeModel(gpu=True, model_type=model_name)\n",
    "\n",
    "    # Train the model (example; adjust parameters as needed)\n",
    "    train.train_seg(\n",
    "        model.net,\n",
    "        train_data=train_images,\n",
    "        train_labels=train_masks,\n",
    "        test_data=val_images, \n",
    "        test_labels=val_masks,\n",
    "        channels=[0, 0],  # Adjust channels if needed\n",
    "        normalize=True,\n",
    "        weight_decay=1e-4,\n",
    "        SGD=False,\n",
    "        learning_rate=0.1,\n",
    "        n_epochs=1000,\n",
    "        save_path=save_path,\n",
    "        model_name=f'{model_name}_cellpose_model.pth'\n",
    "    )\n",
    "\n",
    "    # Evaluate the model and calculate metrics\n",
    "    results_list = []\n",
    "    for i, (image, true_mask) in enumerate(zip(test_images, test_masks)):\n",
    "        results = model.eval(image, channels=[0, 0])\n",
    "        if len(results) == 3:\n",
    "            masks_pred, flows, styles = results\n",
    "        else:\n",
    "            masks_pred, flows, styles, diams = results\n",
    "\n",
    "        metrics = calculate_metrics(true_mask, masks_pred)\n",
    "        results_list.append({\n",
    "            'Image_Index': i,\n",
    "            'Dice_Score': metrics['Dice Score'],\n",
    "            'IoU_Score': metrics['IoU Score'],\n",
    "            'Pixel_Accuracy': metrics['Pixel Accuracy'],\n",
    "            'Number_of_True_ROIs': metrics['Number of True ROIs'],\n",
    "            'Number_of_Predicted_ROIs': metrics['Number of Predicted ROIs']\n",
    "        })\n",
    "\n",
    "    # After training and visualization, delete references\n",
    "    del model\n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    # Clear CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Convert the list of results to a DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Append model name to results and add to all_results_df\n",
    "    results_df['Model_Name'] = model_name\n",
    "    all_results_df = pd.concat([all_results_df, results_df], ignore_index=True)\n",
    "\n",
    "    # Save model-specific results to a CSV file\n",
    "    results_df.to_csv(os.path.join(save_path, f'{model_name}_results.csv'), index=False)\n",
    "\n",
    "    # Visualize and save plots for a subset of test images\n",
    "    random_indices = random.sample(range(len(test_images)), 20)\n",
    "    for idx in random_indices:\n",
    "        results = model.eval(test_images[idx], channels=[0, 0])\n",
    "        if len(results) == 3:\n",
    "            masks_pred, flows, styles = results\n",
    "        else:\n",
    "            masks_pred, flows, styles, diams = results\n",
    "\n",
    "        metrics = calculate_metrics(test_masks[idx], masks_pred)\n",
    "        title = (f\"Image_Index: {idx}, \"\n",
    "                f\"Dice_Score: {metrics['Dice Score']:.2f}, \"\n",
    "                f\"IoU_Score: {metrics['IoU Score']:.2f}, \"\n",
    "                f\"Pixel_Accuracy: {metrics['Pixel Accuracy']:.2f}, \"\n",
    "                f\"Number_of_True_ROIs: {metrics['Number of True ROIs']}, \"\n",
    "                f\"Number_of_Predicted_ROIs: {metrics['Number of Predicted ROIs']}\")\n",
    "\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(16, 6))\n",
    "        fig.suptitle(title, fontsize=12)\n",
    "\n",
    "        ax[0].imshow(test_images[idx])\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(test_images[idx], cmap='gray')\n",
    "        ax[1].imshow(test_masks[idx], cmap='jet', alpha=0.5)\n",
    "        ax[1].set_title('Ground Truth Mask')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(test_images[idx], cmap='gray')\n",
    "        ax[2].imshow(masks_pred, cmap='jet', alpha=0.5)\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        ax[3].imshow(flows[0], cmap='gray')\n",
    "        ax[3].set_title('Flow Field')\n",
    "        ax[3].axis('off')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(save_path, f'{model_name}_image_{idx}.png'), bbox_inches='tight')\n",
    "        plt.close(fig)  # Close the figure to prevent it from being displayed\n",
    "\n",
    "# Save combined results to a CSV file\n",
    "all_results_df.to_csv(os.path.join(save_path, 'all_models_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
